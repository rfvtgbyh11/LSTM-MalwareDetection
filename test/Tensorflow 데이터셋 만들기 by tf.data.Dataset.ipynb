{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0-dev20200426'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 생성\n"
     ]
    }
   ],
   "source": [
    "print(\"데이터셋 생성\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (), types: tf.int32>\n"
     ]
    }
   ],
   "source": [
    "dataset1 = tf.data.Dataset.from_tensor_slices([8, 3, 0, 8, 2, 1])\n",
    "print(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "3\n",
      "0\n",
      "8\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for elem in dataset1:\n",
    "    print(elem.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3 6 3 9 7 9 2 5 7 8]\n",
      " [6 2 9 2 1 7 5 9 4 6]\n",
      " [9 3 7 6 5 3 5 3 1 4]\n",
      " [4 5 4 4 7 9 6 8 3 8]], shape=(4, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "randomTensor = tf.random.uniform([4, 10], minval=1, maxval=10, dtype=tf.int32)\n",
    "print(randomTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (10,), types: tf.int32>\n"
     ]
    }
   ],
   "source": [
    "dataset2 = tf.data.Dataset.from_tensor_slices(randomTensor)\n",
    "print(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 6 3 9 7 9 2 5 7 8]\n",
      "[6 2 9 2 1 7 5 9 4 6]\n",
      "[9 3 7 6 5 3 5 3 1 4]\n",
      "[4 5 4 4 7 9 6 8 3 8]\n"
     ]
    }
   ],
   "source": [
    "for elem in dataset2:\n",
    "    print(elem.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: ((), (10,)), types: (tf.float32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "dataset3 = tf.data.Dataset.from_tensor_slices(\n",
    "    (tf.random.uniform([4]), tf.random.uniform([4, 10], maxval=10, dtype=tf.int32)))\n",
    "\n",
    "print(dataset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=float32, numpy=0.1354729>, <tf.Tensor: shape=(10,), dtype=int32, numpy=array([2, 8, 1, 1, 1, 8, 2, 9, 6, 2])>)\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=0.049445152>, <tf.Tensor: shape=(10,), dtype=int32, numpy=array([4, 5, 8, 4, 8, 4, 3, 0, 2, 9])>)\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=0.6399467>, <tf.Tensor: shape=(10,), dtype=int32, numpy=array([9, 8, 9, 5, 6, 1, 3, 1, 3, 4])>)\n",
      "(<tf.Tensor: shape=(), dtype=float32, numpy=0.068704605>, <tf.Tensor: shape=(10,), dtype=int32, numpy=array([4, 2, 6, 7, 7, 7, 4, 8, 4, 1])>)\n"
     ]
    }
   ],
   "source": [
    "for elem in dataset3:\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ZipDataset shapes: ((10,), ((), (10,))), types: (tf.int32, (tf.float32, tf.int32))>\n"
     ]
    }
   ],
   "source": [
    "dataset4 = tf.data.Dataset.zip((dataset2, dataset3))\n",
    "print(dataset4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FlatMapDataset shapes: (), types: tf.int32>\n"
     ]
    }
   ],
   "source": [
    "def count(stop):\n",
    "    i = 0\n",
    "    while i < stop:\n",
    "        yield i #iterable를 만드는 키워드(여기서는 (0, 1, 2, ..., stop-1)를 차례차례로 반환)\n",
    "        i += 1\n",
    "        \n",
    "dataset5 = tf.data.Dataset.from_generator(\n",
    "    count, args=[4], #count generator에 args(stop) = 4를 집어넣는다는 의미로 보임\n",
    "    output_types=tf.int32, output_shapes=())\n",
    "print(dataset5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for elem in dataset5:\n",
    "    print(elem.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 변형\n"
     ]
    }
   ],
   "source": [
    "print(\"데이터셋 변형\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for elem in dataset5.repeat(2):\n",
    "    print(elem.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인덱스 2의 데이터까지 사용\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(\"인덱스 2의 데이터까지 사용\")\n",
    "for elem in dataset5.take(2):\n",
    "    print(elem.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인덱스 2의 데이터부터 사용\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(\"인덱스 2의 데이터부터 사용\")\n",
    "for elem in dataset5.skip(2):\n",
    "    print(elem.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 왼쪽 차원을 일정 단위로 묶음\n",
      "ex. shape = (4)의 dataset5의 경우 shape = (2)의 데이터 2개로 분할\n",
      "[0 1]\n",
      "[2 3]\n",
      "\n",
      "ex2. shape = (12, 10)의 dataset2.repeat(3)의 경우 shape(3, 10)의 데이터 4개로 분할\n",
      "tf.Tensor(\n",
      "[[3 6 3 9 7 9 2 5 7 8]\n",
      " [6 2 9 2 1 7 5 9 4 6]\n",
      " [9 3 7 6 5 3 5 3 1 4]], shape=(3, 10), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[4 5 4 4 7 9 6 8 3 8]\n",
      " [3 6 3 9 7 9 2 5 7 8]\n",
      " [6 2 9 2 1 7 5 9 4 6]], shape=(3, 10), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[9 3 7 6 5 3 5 3 1 4]\n",
      " [4 5 4 4 7 9 6 8 3 8]\n",
      " [3 6 3 9 7 9 2 5 7 8]], shape=(3, 10), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[6 2 9 2 1 7 5 9 4 6]\n",
      " [9 3 7 6 5 3 5 3 1 4]\n",
      " [4 5 4 4 7 9 6 8 3 8]], shape=(3, 10), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(\"가장 왼쪽 차원을 일정 단위로 묶음\")\n",
    "print(\"ex. shape = (4)의 dataset5의 경우 shape = (2)의 데이터 2개로 분할\")\n",
    "for elem in dataset5.batch(2):\n",
    "    print(elem.numpy())\n",
    "\n",
    "print(\"\\nex2. shape = (12, 10)의 dataset2.repeat(3)의 경우 shape(3, 10)의 데이터 4개로 분할\")\n",
    "for elem in dataset2.repeat(3).batch(3):\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋의 순서를 섞음\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "0\n",
      "3\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(\"데이터셋의 순서를 섞음\")\n",
    "for elem in dataset5.repeat(2).shuffle(buffer_size=10):\n",
    "    print(elem.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 데이터셋을 연결\n",
      "<ConcatenateDataset shapes: (), types: tf.int32>\n",
      "8\n",
      "3\n",
      "0\n",
      "8\n",
      "2\n",
      "1\n",
      "8\n",
      "3\n",
      "0\n",
      "8\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(\"두 데이터셋을 연결\")\n",
    "dataset6 = dataset1.concatenate(dataset1)\n",
    "print(dataset6)\n",
    "for elem in dataset6:\n",
    "    print(elem.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "함수를 사용하여 맵핑\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(\"함수를 사용하여 맵핑\")\n",
    "f = lambda x: 2*x\n",
    "for elem in dataset5.map(f):\n",
    "    print(elem.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "함수의 조건을 만족하는 (반환값이 true인) 데이터만 출력\n",
      "0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(\"함수의 조건을 만족하는 (반환값이 true인) 데이터만 출력\")\n",
    "f = lambda x: x%2 == 0\n",
    "for elem in dataset5.filter(f):\n",
    "    print(elem.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- 실험용코드 ----------------\n",
      "<BatchDataset shapes: (None, 3), types: tf.int32>\n",
      "tf.Tensor(\n",
      "[[7 3 5]\n",
      " [1 7 9]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 3 1]\n",
      " [3 5 4]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(\"--------------- 실험용코드 ----------------\")\n",
    "dataset1 = tf.random.uniform([4, 3], minval = 1, maxval = 10, dtype = tf.int32)\n",
    "dataset1 = tf.data.Dataset.from_tensor_slices(dataset1)\n",
    "dataset1 = dataset1.batch(2)\n",
    "print(dataset1)\n",
    "for i in dataset1:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: (None, 3), types: tf.int32>\n",
      "tf.Tensor(\n",
      "[[9 6 2]\n",
      " [7 6 2]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[2 5 1]\n",
      " [5 2 6]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset2 = tf.random.uniform([4, 3], minval = 1, maxval = 10, dtype = tf.int32)\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices(dataset2)\n",
    "dataset2 = dataset2.batch(2)\n",
    "print(dataset2)\n",
    "for i in dataset2:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ConcatenateDataset shapes: (None, 3), types: tf.int32>\n",
      "tf.Tensor(\n",
      "[[7 3 5]\n",
      " [1 7 9]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 3 1]\n",
      " [3 5 4]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[9 6 2]\n",
      " [7 6 2]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[2 5 1]\n",
      " [5 2 6]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset3 = dataset1.concatenate(dataset2)\n",
    "print(dataset3)\n",
    "for i in dataset3:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ConcatenateDataset' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-986abc564e62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'ConcatenateDataset' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "dataset3.reshape(axis=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
